{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.spatial\n",
    "import tensorflow as tf \n",
    "import sklearn.naive_bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets = pd.read_csv('/Users/juliachen/Desktop/DSCI552/hw/hw5/data/ps5_tweets_text.csv')\n",
    "train_label = pd.read_csv('/Users/juliachen/Desktop/DSCI552/hw/hw5/data/ps5_tweets_labels_as_numbers.csv')\n",
    "\n",
    "test_tweets = pd.read_csv('/Users/juliachen/Desktop/DSCI552/hw/hw5/data/ps5_tweets_text_for_the_kaggle_competition.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape (37041, 2)\n",
      "Test data shape (3798, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train data shape {train_tweets.shape}\")\n",
    "print(f\"Test data shape {test_tweets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'''delete id column'''\n",
    "train_tweets.drop(\"Id\",axis=1,inplace=True)\n",
    "train_label.drop(\"Id\",axis=1,inplace=True)\n",
    "\n",
    "'''Combine train_tweets and train_label into train data set'''\n",
    "train = pd.concat([train_label, train_tweets], axis=1)\n",
    "\n",
    "#train.to_csv(\"/Users/juliachen/Desktop/DSCI552/hw/hw5/data/train.csv\")\n",
    "#train = pd.read_csv('/Users/juliachen/Desktop/DSCI552/hw/hw5/data/train.csv')\n",
    "#train = train.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>https://t.co/UpjxfOgQs8\\r\\r\\n\\r\\r\\nGaisss! Ple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@mygovindia Today just after a week of lockdow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Tuskys partners with Amref to provide on groun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>@chrissyteigen are u doing ur own grocery shop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>UK Critical Care Nurse Cries at Empty SuperMar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                              Tweet\n",
       "0      4  https://t.co/UpjxfOgQs8\\r\\r\\n\\r\\r\\nGaisss! Ple...\n",
       "1      1  @mygovindia Today just after a week of lockdow...\n",
       "2      2  Tuskys partners with Amref to provide on groun...\n",
       "3      1  @chrissyteigen are u doing ur own grocery shop...\n",
       "4      0  UK Critical Care Nurse Cries at Empty SuperMar..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    10282\n",
       "1     8930\n",
       "2     6930\n",
       "4     5953\n",
       "0     4946\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://t.co/UpjxfOgQs8\\r\\r\\n\\r\\r\\nGaisss! Ple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@mygovindia Today just after a week of lockdow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tuskys partners with Amref to provide on groun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@chrissyteigen are u doing ur own grocery shop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UK Critical Care Nurse Cries at Empty SuperMar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet\n",
       "0  https://t.co/UpjxfOgQs8\\r\\r\\n\\r\\r\\nGaisss! Ple...\n",
       "1  @mygovindia Today just after a week of lockdow...\n",
       "2  Tuskys partners with Amref to provide on groun...\n",
       "3  @chrissyteigen are u doing ur own grocery shop...\n",
       "4  UK Critical Care Nurse Cries at Empty SuperMar..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        https://t.co/UpjxfOgQs8\\r\\r\\n\\r\\r\\nGaisss! Ple...\n",
       "1        @mygovindia Today just after a week of lockdow...\n",
       "2        Tuskys partners with Amref to provide on groun...\n",
       "3        @chrissyteigen are u doing ur own grocery shop...\n",
       "4        UK Critical Care Nurse Cries at Empty SuperMar...\n",
       "                               ...                        \n",
       "37036    Minnesota classifies grocery store workers as ...\n",
       "37037    US Senator @ewarren has asked for information ...\n",
       "37038    Just commented on @thejournal_ie: Poll: Are yo...\n",
       "37039    My wife got laid off yesterday because the sma...\n",
       "37040    Humanity is doomed\\r\\r\\n#coronavirus #coronacr...\n",
       "Name: Tweet, Length: 37041, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets['Tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of tokenization is to represent words in a way that computer can understand and be able to train it. \n",
    "\n",
    "num_words: the maximum number of words to keep, based on word frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#tokenizer = Tokenizer(num_words=10000)\n",
    "                      #filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                      #lower=True,\n",
    "                      #split=\" \")\n",
    "\n",
    "            \n",
    "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>',\n",
    "                     filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                     lower=True)\n",
    "            \n",
    "            \n",
    "tokenizer.fit_on_texts(train_tweets['Tweet'])\n",
    "\n",
    "word_index= tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_train = tokenizer.texts_to_matrix(train_tweets['Tweet'], mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Split training and validation set'''\n",
    "\n",
    "\"\"\"Create random indices\"\"\"\n",
    "np.random.seed(42)\n",
    "N = len(train_tweets)\n",
    "shuffled_indices = np.random.permutation(N)\n",
    "train_label=train_label.to_numpy()\n",
    "\n",
    "\"\"\"Split indices into train and val set\"\"\"\n",
    "train_indices = shuffled_indices[:int(N*0.8)]\n",
    "valid_indices = shuffled_indices[int(N*0.8):]\n",
    "\n",
    "\"\"\"Spilt\"\"\"\n",
    "training_sentences = one_hot_train[train_indices]\n",
    "training_labels = train_label[train_indices]\n",
    "\n",
    "valid_sentences = one_hot_train[valid_indices]\n",
    "valid_labels = train_label[valid_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11836, 35248, 23784, ..., 27958,  8399,  9079])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shape of training x (29632, 5000)\n",
      "The Shape of testing x (7409, 5000)\n",
      "The Shape of training y (29632, 1)\n",
      "The Shape of testing y (7409, 1)\n"
     ]
    }
   ],
   "source": [
    "print('The Shape of training x',training_sentences.shape)\n",
    "print('The Shape of testing x',valid_sentences.shape)\n",
    "\n",
    "print('The Shape of training y',training_labels.shape)\n",
    "print('The Shape of testing y',valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ExN = np.array(valid_labels==0).astype('int')\n",
    "train_Neg = np.array(valid_labels==1).astype('int')\n",
    "train_Neu = np.array(valid_labels==2).astype('int')\n",
    "train_Pos = np.array(valid_labels==3).astype('int')\n",
    "train_ExP = np.array(valid_labels==4).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes = sklearn.naive_bayes.MultinomialNB()\n",
    "bayes.fit(training_sentences, training_labels.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, ..., 3, 2, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction1 = bayes.predict(valid_sentences)\n",
    "prediction1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.48616547442299907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.48      0.49       991\n",
      "           1       0.43      0.46      0.44      1755\n",
      "           2       0.65      0.53      0.58      1645\n",
      "           3       0.40      0.45      0.42      1810\n",
      "           4       0.54      0.54      0.54      1208\n",
      "\n",
      "    accuracy                           0.49      7409\n",
      "   macro avg       0.50      0.49      0.49      7409\n",
      "weighted avg       0.50      0.49      0.49      7409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Accuracy: ',metrics.accuracy_score(prediction1, valid_labels))\n",
    "#print('F1 Score:', metrics.f1_score(prediction1, valid_labels, average='weighted'))\n",
    "\n",
    "print(metrics.classification_report(prediction1, valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 score:  0.48616547442299907\n",
      "Macro F1 score:  0.49425341334830347\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(\"Micro F1 score: \",f1_score(valid_labels, prediction1, average='micro'))\n",
    "print(\"Macro F1 score: \",f1_score(valid_labels, prediction1, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
